# 橋梁維持管理 Agentic Clustering v0.3

山口県の橋梁維持管理データを用いた自己改善型クラスタリングシステム

## 🎯 主な内容

### プロジェクトの成果

本プロジェクトでは、**山口県の4,292件の橋梁データ**を対象に、自己改善型のAgenticクラスタリングシステムを構築しました。

#### ✨ 主要な達成事項

1. **11個の特徴量による多角的分析**
   - 基本特徴量（橋齢、健全度、補修優先度等）：6個
   - 拡張特徴量（構造形式、橋面積、緊急輸送道路等）：5個

2. **3つのクラスタリング手法の自動評価**
   - KMeans（k=2〜28の自動探索）
   - GMM（Gaussian Mixture Model）
   - **DBSCAN（密度ベース）← 最適手法として選択**

3. **3つの次元削減手法の自動評価**
   - **PCA（主成分分析）← 最適手法として選択**
   - t-SNE（t-distributed Stochastic Neighbor Embedding）
   - UMAP（Uniform Manifold Approximation and Projection）

4. **最終結果**
   - 選択手法：DBSCAN（34クラスタ）
   - 総合スコア：51.20/100
   - シルエットスコア：0.257
   - Davies-Bouldin指数：0.989

#### 📊 実装の特徴

- **自己改善ループ**: 品質閾値を下回った場合、自動的に代替手法を試行
- **目標ベース最適化**: DBSCANのクラスタ数を目標値（50）に基づいて調整
- **包括的な可視化**: 散布図、ヒートマップ、レーダーチャート、箱ひげ図等
- **詳細なログ記録**: 改善履歴とパラメータ選択の根拠を自動記録

#### 🔑 重要な教訓

1. **データ構造の理解**: Excelのマルチヘッダー対応が必須
2. **評価指標の選択**: Calinski-Harabasz指数は高次元で過大評価される
3. **パラメータ調整**: 目標クラスタ数に基づくスコア調整で実用的な結果を実現
4. **欠損値戦略**: データの意味を考慮した補完（平均値、5パーセンタイル値等）
5. **反復改善**: 130→28→67→**34クラスタ**と段階的に最適化

#### 💻 技術スタック

- Python 3.12
- scikit-learn 1.7.2（KMeans、GMM、DBSCAN、t-SNE）
- umap-learn 0.5.9（UMAP）
- pandas 2.3.3（データ処理）
- matplotlib / seaborn（可視化）

---

## 📋 目次

1. [概要](#概要)
2. [システム構成](#システム構成)
3. [特徴量設計](#特徴量設計)
4. [実装の教訓](#実装の教訓)
5. [パラメータ最適化の履歴](#パラメータ最適化の履歴)
6. [実行結果](#実行結果)
7. [使用方法](#使用方法)
8. [技術スタック](#技術スタック)

---

## 概要

### プロジェクトの目的

山口県の橋梁維持管理データ（4,292件）を対象に、**Agenticクラスタリング**による自己改善型の分類システムを構築。クラスタリング手法と次元削減手法を自動的に評価・選択し、最適な橋梁グループ化を実現する。

### 主要機能

- ✅ **3つのクラスタリング手法**の自動評価・比較（KMeans、GMM、DBSCAN）
- ✅ **3つの次元削減手法**の自動評価・比較（PCA、t-SNE、UMAP）
- ✅ **11個の特徴量**による多角的分析
- ✅ **自己改善ループ**による品質向上
- ✅ **包括的な可視化**（散布図、ヒートマップ、レーダーチャート等）

---

## システム構成

### モジュール構成

```
agentic-clustering/
├── config.py                    # 設定ファイル
├── data_preprocessing.py        # データ前処理
├── cluster_evaluator.py         # クラスタ評価
├── alternative_methods.py       # 代替手法（GMM、DBSCAN、t-SNE、UMAP）
├── agentic_workflow.py          # Agenticワークフロー
├── visualization.py             # 可視化
├── run_all.py                   # メイン実行スクリプト
├── data/                        # データディレクトリ
│   ├── YamaguchiPrefBridgeListOpen251122_154891.xlsx
│   ├── 全市町村の主要財政指標_000917808.xlsx
│   └── 市区町村別年齢階級別人口_2304ssnen.xlsx
└── output/                      # 出力ディレクトリ
    ├── cluster_results.csv
    ├── cluster_summary.csv
    ├── agentic_improvement_log.txt
    └── *.png (可視化画像)
```

### ワークフロー

```
1. データ前処理
   ↓
2. 初回クラスタリング（KMeans）
   ↓
3. 品質評価（総合スコア計算）
   ↓
4. 代替手法の試行（GMM、DBSCAN）
   ↓
5. 最適手法の選択
   ↓
6. 次元削減（PCA → 必要に応じてt-SNE、UMAP）
   ↓
7. 結果の可視化・保存
```

---

## 特徴量設計

### 基本特徴量（6個）

| 特徴量名 | 説明 | データソース |
|---------|------|------------|
| `bridge_age` | 橋齢（年） | 架設年から計算 |
| `condition_score` | 健全度スコア（1-4） | 健全度Ⅰ〜Ⅳ |
| `maintenance_priority` | 補修優先度 | 橋齢 × 健全度 |
| `future_burden_ratio` | 将来負担比率（%） | 財政データ |
| `aging_rate` | 高齢化率（%） | 人口統計データ |
| `fiscal_index` | 財政力指数 | 財政データ |

### 拡張特徴量（5個）- v0.3で追加

| 特徴量名 | 説明 | 処理方法 |
|---------|------|---------|
| `structure_category` | 構造形式カテゴリ（1-5） | RC系、PC系、鋼橋、ボックス系、その他 |
| `bridge_area` | 橋面積（m²） | 橋長 × 幅員 |
| `emergency_route` | 緊急輸送道路（0/1） | ダミー変数化 |
| `overpass` | 跨線橋（0/1） | ダミー変数化 |
| `repair_year_normalized` | 最新補修年度（0-1） | Min-Max正規化（1989-2022年） |

### 特徴量の統計

```
構造形式分布:
  - RC系: 2,446件（57.0%）
  - PC系: 1,475件（34.4%）
  - 鋼橋: 297件（6.9%）
  - ボックス系: 55件（1.3%）
  - その他: 19件（0.4%）

橋面積: 平均223.8m²、中央値66.9m²
緊急輸送道路: 2,036件（47.4%）
跨線橋: 88件（2.1%）
補修実施: 642件（15.0%）
```

---

## 実装の教訓

### 1. データ読み込みの教訓

#### 問題
Excelファイルが**マルチヘッダー構造**（0行目と1行目にヘッダー）を持っていた。

#### 解決策
```python
# マルチヘッダーを読み込み、列名を単純化
df = pd.read_excel(BRIDGE_DATA_FILE, header=[0, 1])
df.columns = [col[0] if 'Unnamed' in str(col[1]) else col[0] for col in df.columns]
```

### 2. 評価指標の最適化

#### 試行錯誤の履歴

| バージョン | 評価重み | 結果 |
|-----------|---------|------|
| v0.1 | Silhouette:DBI:CH:Balance = 40:30:20:10 | 基準設定 |
| v0.2 | 50:50:0:0 | CHの影響を排除 |
| v0.3 | 45:45:0:10 | バランスを再考慮（最終版） |

**教訓**: Calinski-Harabasz指数は高次元データで過度に楽観的な評価を与える傾向があるため、重みを0%とした。

### 3. クラスタ数の最適化

#### DBSCANパラメータの調整履歴

| 試行 | 目標クラスタ数 | eps範囲 | min_samples範囲 | 結果 |
|-----|--------------|---------|----------------|------|
| 初期 | なし | 0.5-2.0 | 5-20 | 130クラスタ（細分化過剰） |
| 第1改善 | 30 | 1.0-3.0 | 10-50 | 28クラスタ |
| 第2改善 | 60 | 0.7-1.5 | 10-30 | 67クラスタ |
| **最終** | **50** | **0.8-1.6** | **15-35** | **34クラスタ** ✅ |

**教訓**: 目標クラスタ数に基づくスコア調整を導入することで、実用的なクラスタ数を実現。

### 4. 次元削減の教訓

#### オーバーラップ閾値の調整

| バージョン | 閾値 | 影響 |
|-----------|-----|------|
| v0.1 | 0.3 | PCAで容易に通過 |
| v0.2 | 0.1 | 代替手法の試行頻度増加 |
| **v0.3** | **0.05** | より厳格な分離要求 ✅ |

#### t-SNEの実装修正

**問題**: `n_iter`パラメータが非推奨

**解決策**:
```python
# 修正前（エラー）
tsne = TSNE(n_iter=1000)

# 修正後
tsne = TSNE(max_iter=1000, n_iter_without_progress=300)
```

### 5. 欠損値処理の戦略

#### 市町村データの欠損値補完

| データ | 欠損率 | 補完方法 | 根拠 |
|-------|-------|---------|------|
| 財政指標 | 約37% | 平均値 | 県内の平均的財政状況を仮定 |
| 人口統計 | 約32% | 5パーセンタイル値 | 小規模町村の特性を反映 |
| 補修年度 | 85% | 0（補修なし） | 実際に補修されていない |

**教訓**: データの意味を考慮した補完方法の選択が重要。

---

## パラメータ最適化の履歴

### 現在の最適パラメータ（v0.3）

```python
# クラスタリング
MIN_CLUSTERS = 2
MAX_CLUSTERS = 28  # 市町村数（19）× 1.5
OVERLAP_THRESHOLD = 0.05

# 評価重み
EVALUATION_WEIGHTS = {
    'silhouette': 0.45,
    'davies_bouldin': 0.45,
    'calinski_harabasz': 0.0,
    'balance': 0.10
}

# DBSCAN（目標クラスタ数: 50）
DBSCAN_EPS_RANGE = [0.8, 1.0, 1.2, 1.4, 1.6]
DBSCAN_MIN_SAMPLES_RANGE = [15, 20, 25, 30, 35]
DBSCAN_TARGET_CLUSTERS = 50
DBSCAN_NOISE_THRESHOLD = 0.35  # 35%まで許容
DBSCAN_CLUSTER_RANGE = (20, 100)  # クラスタ数の妥当な範囲
```

---

## 実行結果

### 最終実行結果（v0.3）

```
総データ数: 4,292件
特徴量数: 11個
```

#### クラスタリング手法の比較

| 順位 | 手法 | 総合スコア | シルエット | DBI | クラスタ数 |
|-----|------|-----------|-----------|-----|----------|
| 🥇 | **DBSCAN** | **51.20** | 0.257 | 0.989 | **34** |
| 🥈 | KMeans | 47.41 | 0.229 | 1.314 | 24 |
| 🥉 | GMM | 45.41 | 0.375 | 2.282 | 2 |

#### 次元削減手法の比較

| 順位 | 手法 | オーバーラップスコア |
|-----|------|-------------------|
| 🥇 | **PCA** | **0.1458** |
| 🥈 | UMAP | 0.5991 |
| 🥉 | t-SNE | 1.1976 |

**選択理由**: PCAが最も低いオーバーラップスコアを示し、クラスタの分離に優れている。

#### DBSCANの詳細結果

```
最適パラメータ:
  - eps: 1.2
  - min_samples: 15
  - クラスタ数: 34（目標50に対して68%達成）
  - ノイズ: 1,347件（31.4%）

主要クラスタ分布:
  1. クラスタ5: 497件（11.6%）
  2. クラスタ1: 368件（8.6%）
  3. クラスタ8: 282件（6.6%）
  4. クラスタ0: 205件（4.8%）
  5. クラスタ7: 191件（4.5%）
```

### 改善の履歴

```
ラウンド1: KMeans (k=24) → スコア 47.41
           ↓ 閾値60.0を下回る
ラウンド2: 代替手法の試行
           - GMM (n=2) → スコア 45.41
           - DBSCAN (34クラスタ) → スコア 51.20 ✓
           ↓
次元削減: PCA → オーバーラップ 0.1458 > 0.05
           ↓ 閾値を超える
代替試行: t-SNE、UMAP
           ↓
最終選択: PCA（最も分離が良好）
```

---

## 使用方法

### 環境構築

```bash
# Python仮想環境の作成
python -m venv venv

# 仮想環境の有効化
# Windows PowerShell:
.\venv\Scripts\Activate.ps1

# パッケージのインストール
pip install pandas numpy scikit-learn matplotlib seaborn umap-learn openpyxl
```

### データ準備

必要なデータファイルを`data/`ディレクトリに配置:

1. `YamaguchiPrefBridgeListOpen251122_154891.xlsx` - 橋梁データ
2. `全市町村の主要財政指標_000917808.xlsx` - 財政データ
3. `市区町村別年齢階級別人口_2304ssnen.xlsx` - 人口統計データ

### 実行

```bash
# 全ステップの実行
python run_all.py

# または個別実行
python data_preprocessing.py        # 前処理のみ
python agentic_workflow.py          # クラスタリングのみ
python visualization.py             # 可視化のみ
```

### 出力ファイル

```
output/
├── processed_bridge_data.csv       # 前処理済みデータ
├── cluster_results.csv             # クラスタリング結果
├── cluster_summary.csv             # クラスタサマリー
├── agentic_improvement_log.txt     # 改善ログ
├── cluster_pca_scatter.png         # PCA散布図
├── cluster_heatmap.png             # 特徴量ヒートマップ
├── cluster_radar.png               # レーダーチャート
├── cluster_distribution.png        # クラスタ分布
├── feature_boxplots.png            # 箱ひげ図
└── cluster_report.txt              # 分析レポート
```

---

## 技術スタック

### コアライブラリ

| ライブラリ | バージョン | 用途 |
|-----------|-----------|------|
| Python | 3.12 | 実行環境 |
| pandas | 2.3.3 | データ処理 |
| numpy | 1.26+ | 数値計算 |
| scikit-learn | 1.7.2 | 機械学習 |
| umap-learn | 0.5.9 | 次元削減（UMAP） |
| matplotlib | 3.8+ | 可視化 |
| seaborn | 0.13+ | 統計的可視化 |
| openpyxl | 3.1+ | Excelファイル読み込み |

### アルゴリズム

#### クラスタリング

- **KMeans**: エルボー法 + シルエット分析で最適k探索
- **GMM** (Gaussian Mixture Model): BICベースのコンポーネント数選択
- **DBSCAN**: 密度ベース、目標クラスタ数に基づくグリッドサーチ

#### 次元削減

- **PCA** (Principal Component Analysis): 線形次元削減
- **t-SNE**: 非線形、局所構造保存
- **UMAP** (Uniform Manifold Approximation and Projection): 非線形、グローバル構造保存

#### 評価指標

- **Silhouette Score**: クラスタ内凝集度とクラスタ間分離度
- **Davies-Bouldin Index**: クラスタの分離度（低いほど良い）
- **Calinski-Harabasz Index**: クラスタの分散比（高いほど良い）※v0.3では重み0
- **Balance Score**: クラスタサイズの均等性

---

## 今後の改善案

### 短期的改善

1. **特徴量エンジニアリング**
   - 橋梁の交通量データの統合
   - 地理的クラスタリング（緯度・経度）の追加
   - 過去の補修履歴の時系列分析

2. **パラメータチューニング**
   - QUALITY_THRESHOLDの動的調整
   - クラスタ数の自動提案機能

3. **可視化の強化**
   - インタラクティブなダッシュボード（Plotly、Streamlit）
   - 地図上への橋梁プロット

### 長期的改善

1. **深層学習の導入**
   - オートエンコーダによる特徴抽出
   - クラスタリングとの統合（Deep Embedded Clustering）

2. **予測モデルの構築**
   - 将来の健全度予測
   - 補修時期の最適化

3. **実用化対応**
   - Web APIの構築
   - リアルタイム分析機能
   - 他自治体データへの汎化

---

## まとめ

### 達成した成果

✅ 11個の特徴量による多角的な橋梁分析  
✅ 3つのクラスタリング手法の自動評価・比較  
✅ 3つの次元削減手法の自動評価・比較  
✅ 目標クラスタ数に基づく最適化機能  
✅ 包括的な可視化機能  
✅ 自己改善型のAgenticワークフロー  

### 重要な教訓

1. **データ構造の理解が最優先** - マルチヘッダーなどの特殊構造に対応
2. **評価指標の選択が結果を左右** - CHスコアの過大評価に注意
3. **目標に基づくパラメータ調整** - 実用的なクラスタ数を実現
4. **欠損値処理の戦略** - データの意味を考慮した補完
5. **反復的な改善プロセス** - 試行錯誤から最適解を発見

### プロジェクトの意義

本システムは、橋梁維持管理における**データドリブンな意思決定**を支援し、限られた予算内での効率的な補修計画立案に貢献する。Agenticアプローチにより、人手を介さずに最適な分析手法を選択できる点が革新的である。

---

**作成日**: 2025年11月24日  
**バージョン**: v0.3  
**作成者**: Agentic Clustering Project Team
