# -*- coding: utf-8 -*-
"""
Agenticã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼: v0.2
è‡ªå·±è©•ä¾¡ã¨æ”¹å–„ã‚’ç¹°ã‚Šè¿”ã™è³¢ã„ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ 
"""

import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
import config
from cluster_evaluator import ClusterEvaluator, DimensionalityReductionEvaluator, compare_methods
from alternative_methods import AlternativeClusteringMethods, AlternativeDimensionalityReduction

class AgenticClusteringWorkflow:
    """Agenticã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã®ãƒ¡ã‚¤ãƒ³ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼"""
    
    def __init__(self, df, feature_cols):
        """
        Parameters:
        -----------
        df : DataFrame
            å‰å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿
        feature_cols : list
            ä½¿ç”¨ã™ã‚‹ç‰¹å¾´é‡ã®ã‚«ãƒ©ãƒ åãƒªã‚¹ãƒˆ
        """
        self.df = df
        self.feature_cols = feature_cols
        self.X = df[feature_cols].fillna(0)
        self.X_scaled = None
        self.scaler = None
        
        # çµæœã‚’ä¿å­˜
        self.clustering_results = {}
        self.evaluation_results = {}
        self.dimensionality_results = {}
        self.dim_evaluation_results = {}
        
        # æœ€çµ‚çš„ãªé¸æŠ
        self.best_clustering_method = None
        self.best_clustering_labels = None
        self.best_dim_reduction_method = None
        self.best_dim_reduction_embedding = None
        
        # æ”¹å–„å±¥æ­´
        self.improvement_log = []
    
    def run(self, quality_threshold=60.0, overlap_threshold=0.5):
        """
        Agenticãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’å®Ÿè¡Œ
        
        Parameters:
        -----------
        quality_threshold : float
            ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°å“è³ªã®é–¾å€¤ï¼ˆ0-100ï¼‰
        overlap_threshold : float
            æ¬¡å…ƒå‰Šæ¸›ã®ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—é–¾å€¤ï¼ˆ0-1ï¼‰
        """
        print("\n" + "="*70)
        print("ğŸ¤– Agenticã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ v0.2")
        print("="*70)
        
        # ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ‡ãƒ¼ã‚¿æ¨™æº–åŒ–
        self._standardize_data()
        
        # ã‚¹ãƒ†ãƒƒãƒ—2: åˆå›ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ï¼ˆKMeansï¼‰
        self._log("ã€ãƒ©ã‚¦ãƒ³ãƒ‰1ã€‘åˆå›ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ï¼ˆKMeansï¼‰")
        initial_labels = self._initial_clustering()
        
        # ã‚¹ãƒ†ãƒƒãƒ—3: ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°å“è³ªè©•ä¾¡
        self._log("ã€è©•ä¾¡1ã€‘ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°å“è³ªè©•ä¾¡")
        evaluator = ClusterEvaluator(self.X_scaled, initial_labels)
        initial_scores = evaluator.evaluate_all()
        self.evaluation_results['KMeans'] = initial_scores
        
        # ã‚¹ãƒ†ãƒƒãƒ—4: æ”¹å–„ãŒå¿…è¦ã‹åˆ¤å®š
        needs_improvement = evaluator.needs_improvement(quality_threshold)
        
        if needs_improvement:
            # ã‚¹ãƒ†ãƒƒãƒ—5: ä»£æ›¿ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°æ‰‹æ³•ã®å®Ÿè¡Œ
            self._log("ã€ãƒ©ã‚¦ãƒ³ãƒ‰2ã€‘ä»£æ›¿ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°æ‰‹æ³•ã®è©¦è¡Œ")
            self._try_alternative_clustering()
            
            # ã‚¹ãƒ†ãƒƒãƒ—6: æœ€é©æ‰‹æ³•ã®é¸æŠ
            self._log("ã€é¸æŠã€‘æœ€é©ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°æ‰‹æ³•ã®æ±ºå®š")
            self._select_best_clustering()
        else:
            self.best_clustering_method = 'KMeans'
            self.best_clustering_labels = initial_labels
            self._log("âœ… åˆå›ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã§ååˆ†ãªå“è³ªãŒå¾—ã‚‰ã‚Œã¾ã—ãŸ")
        
        # ã‚¹ãƒ†ãƒƒãƒ—7: æ¬¡å…ƒå‰Šæ¸›ï¼ˆPCAï¼‰
        self._log("ã€ãƒ©ã‚¦ãƒ³ãƒ‰1ã€‘åˆå›æ¬¡å…ƒå‰Šæ¸›ï¼ˆPCAï¼‰")
        initial_embedding = self._initial_dimensionality_reduction()
        
        # ã‚¹ãƒ†ãƒƒãƒ—8: æ¬¡å…ƒå‰Šæ¸›ã®ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—è©•ä¾¡
        self._log("ã€è©•ä¾¡2ã€‘æ¬¡å…ƒå‰Šæ¸›ã®ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—è©•ä¾¡")
        dim_evaluator = DimensionalityReductionEvaluator(
            initial_embedding, 
            self.best_clustering_labels
        )
        pca_overlap = dim_evaluator.evaluate_overlap()
        self.dim_evaluation_results['PCA'] = pca_overlap
        
        # ã‚¹ãƒ†ãƒƒãƒ—9: ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—ãŒé«˜ã„å ´åˆã¯ä»£æ›¿æ‰‹æ³•
        has_overlap = dim_evaluator.has_high_overlap(overlap_threshold)
        
        if has_overlap:
            # ã‚¹ãƒ†ãƒƒãƒ—10: ä»£æ›¿æ¬¡å…ƒå‰Šæ¸›æ‰‹æ³•ã®å®Ÿè¡Œ
            self._log("ã€ãƒ©ã‚¦ãƒ³ãƒ‰2ã€‘ä»£æ›¿æ¬¡å…ƒå‰Šæ¸›æ‰‹æ³•ã®è©¦è¡Œ")
            self._try_alternative_dimensionality_reduction()
            
            # ã‚¹ãƒ†ãƒƒãƒ—11: æœ€é©æ¬¡å…ƒå‰Šæ¸›æ‰‹æ³•ã®é¸æŠ
            self._log("ã€é¸æŠã€‘æœ€é©æ¬¡å…ƒå‰Šæ¸›æ‰‹æ³•ã®æ±ºå®š")
            self._select_best_dimensionality_reduction()
        else:
            self.best_dim_reduction_method = 'PCA'
            self.best_dim_reduction_embedding = initial_embedding
            self._log("âœ… PCAã§ååˆ†ãªåˆ†é›¢ãŒå¾—ã‚‰ã‚Œã¾ã—ãŸ")
        
        # ã‚¹ãƒ†ãƒƒãƒ—12: çµæœã®ã‚µãƒãƒªãƒ¼
        self._print_summary()
        
        return self._prepare_final_results()
    
    def _standardize_data(self):
        """ãƒ‡ãƒ¼ã‚¿ã‚’æ¨™æº–åŒ–"""
        print("\nğŸ“Š ç‰¹å¾´é‡ã‚’æ¨™æº–åŒ–ä¸­...")
        self.scaler = StandardScaler()
        self.X_scaled = self.scaler.fit_transform(self.X)
        print("âœ“ æ¨™æº–åŒ–å®Œäº†")
    
    def _initial_clustering(self):
        """åˆå›ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ï¼ˆKMeansï¼‰"""
        from clustering import find_optimal_clusters, perform_clustering
        
        best_k, best_score, _ = find_optimal_clusters(self.X_scaled)
        kmeans, labels = perform_clustering(self.X_scaled, best_k)
        
        self.clustering_results['KMeans'] = {
            'model': kmeans,
            'labels': labels,
            'n_clusters': best_k
        }
        
        return labels
    
    def _try_alternative_clustering(self):
        """ä»£æ›¿ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°æ‰‹æ³•ã‚’è©¦è¡Œ"""
        alt_methods = AlternativeClusteringMethods(self.X_scaled)
        
        # åˆå›ã®ã‚¯ãƒ©ã‚¹ã‚¿æ•°ã‚’å‚è€ƒå€¤ã¨ã—ã¦ä½¿ç”¨
        reference_k = self.clustering_results['KMeans']['n_clusters']
        
        # GMM (ã‚ªãƒ•: K-Meansã¨åŒæ§˜ã®ã‚¹ã‚³ã‚¢ã®ãŸã‚å®Ÿè¡Œã‚¹ã‚­ãƒƒãƒ—)
        # try:
        #     gmm_labels = alt_methods.try_gmm()
        #     self.clustering_results['GMM'] = alt_methods.results['GMM']
        #     
        #     # è©•ä¾¡
        #     evaluator = ClusterEvaluator(self.X_scaled, gmm_labels)
        #     self.evaluation_results['GMM'] = evaluator.evaluate_all()
        # except Exception as e:
        #     print(f"   âš ï¸ GMMå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        
        # DBSCAN
        try:
            dbscan_labels = alt_methods.try_dbscan()
            self.clustering_results['DBSCAN'] = alt_methods.results['DBSCAN']
            dbscan_n_clusters = alt_methods.results['DBSCAN']['n_clusters']
            
            # è©•ä¾¡ï¼ˆãƒã‚¤ã‚ºãƒã‚¤ãƒ³ãƒˆã‚’é™¤å¤–ï¼‰
            mask = dbscan_labels != -1
            if mask.sum() > 1:
                evaluator = ClusterEvaluator(self.X_scaled[mask], dbscan_labels[mask])
                self.evaluation_results['DBSCAN'] = evaluator.evaluate_all()
            
            # ğŸ†• Agenticãªåˆ¤å®š: DBSCANã®ã‚¯ãƒ©ã‚¹ã‚¿æ•°ãŒé–¾å€¤ã‚’è¶…ãˆã‚‹å ´åˆã¯HDBSCANã‚’è©¦è¡Œ
            if dbscan_n_clusters > config.DBSCAN_CLUSTER_THRESHOLD:
                print(f"\nâš ï¸  DBSCANã®ã‚¯ãƒ©ã‚¹ã‚¿æ•°({dbscan_n_clusters})ãŒé–¾å€¤({config.DBSCAN_CLUSTER_THRESHOLD})ã‚’è¶…ãˆã¦ã„ã¾ã™ã€‚")
                print(f"   â†’ è£œä¿®æ„æ€æ±ºå®šã«ã¯æ‰±ã„ã¥ã‚‰ã„ãŸã‚ã€HDBSCANã‚’ä»£æ›¿æ‰‹æ³•ã¨ã—ã¦è©¦è¡Œã—ã¾ã™ã€‚")
                print(f"   â†’ HDBSCANç›®æ¨™ã‚¯ãƒ©ã‚¹ã‚¿æ•°: {config.HDBSCAN_TARGET_CLUSTERS}")
                
                try:
                    hdbscan_labels = alt_methods.try_hdbscan(target_clusters=config.HDBSCAN_TARGET_CLUSTERS)
                    if hdbscan_labels is not None and 'HDBSCAN' in alt_methods.results:
                        self.clustering_results['HDBSCAN'] = alt_methods.results['HDBSCAN']
                        
                        # è©•ä¾¡ï¼ˆãƒã‚¤ã‚ºãƒã‚¤ãƒ³ãƒˆã‚’é™¤å¤–ï¼‰
                        mask_hdbscan = hdbscan_labels != -1
                        if mask_hdbscan.sum() > 1:
                            evaluator_hdbscan = ClusterEvaluator(self.X_scaled[mask_hdbscan], hdbscan_labels[mask_hdbscan])
                            self.evaluation_results['HDBSCAN'] = evaluator_hdbscan.evaluate_all()
                            print(f"   âœ… HDBSCANã‚’ä»£æ›¿æ‰‹æ³•å€™è£œã«è¿½åŠ ã—ã¾ã—ãŸã€‚")
                except Exception as e:
                    print(f"   âš ï¸ HDBSCANå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
                    
        except Exception as e:
            print(f"   âš ï¸ DBSCANå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
    
    def _select_best_clustering(self):
        """æœ€é©ãªã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°æ‰‹æ³•ã‚’é¸æŠ"""
        # DBSCANã®ã‚¯ãƒ©ã‚¹ã‚¿æ•°ãŒ50ã‚’è¶…ãˆã‚‹å ´åˆã¯å€™è£œã‹ã‚‰é™¤å¤–
        filtered_results = {}
        for method, result in self.evaluation_results.items():
            if method == 'DBSCAN':
                n_clusters = self.clustering_results[method].get('n_clusters', 0)
                if n_clusters > config.DBSCAN_CLUSTER_THRESHOLD:
                    print(f"\nâš ï¸  DBSCANã®ã‚¯ãƒ©ã‚¹ã‚¿æ•°({n_clusters})ãŒé–¾å€¤({config.DBSCAN_CLUSTER_THRESHOLD})ã‚’è¶…ãˆã¦ã„ã‚‹ãŸã‚ã€æ¡ç”¨å€™è£œã‹ã‚‰é™¤å¤–ã—ã¾ã™ã€‚")
                    continue
            filtered_results[method] = result
        
        # ãƒ•ã‚£ãƒ«ã‚¿å¾Œã®å€™è£œã‹ã‚‰æœ€é©æ‰‹æ³•ã‚’é¸æŠ
        if not filtered_results:
            print("\nâš ï¸  ã™ã¹ã¦ã®æ‰‹æ³•ãŒé™¤å¤–ã•ã‚Œã¾ã—ãŸã€‚KMeansã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
            best_method = 'KMeans'
        else:
            best_method, comparison = compare_methods(filtered_results)
        
        self.best_clustering_method = best_method
        self.best_clustering_labels = self.clustering_results[best_method]['labels']
        
        self._log(f"ğŸ¯ é¸æŠã•ã‚ŒãŸæ‰‹æ³•: {best_method}")
    
    def _initial_dimensionality_reduction(self):
        """åˆå›æ¬¡å…ƒå‰Šæ¸›ï¼ˆPCAï¼‰"""
        pca = PCA(n_components=2)
        embedding = pca.fit_transform(self.X_scaled)
        
        explained_variance = pca.explained_variance_ratio_
        print(f"\nğŸ” PCA: èª¬æ˜ã•ã‚ŒãŸåˆ†æ•£ = {explained_variance.sum():.2%}")
        
        self.dimensionality_results['PCA'] = {
            'model': pca,
            'embedding': embedding
        }
        
        return embedding
    
    def _try_alternative_dimensionality_reduction(self):
        """ä»£æ›¿æ¬¡å…ƒå‰Šæ¸›æ‰‹æ³•ã‚’è©¦è¡Œ"""
        alt_dim = AlternativeDimensionalityReduction(self.X_scaled)
        
        # t-SNE
        try:
            tsne_embedding = alt_dim.try_tsne()
            if tsne_embedding is not None:
                self.dimensionality_results['t-SNE'] = alt_dim.results['t-SNE']
                
                # ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—è©•ä¾¡
                evaluator = DimensionalityReductionEvaluator(
                    tsne_embedding,
                    self.best_clustering_labels
                )
                self.dim_evaluation_results['t-SNE'] = evaluator.evaluate_overlap()
        except Exception as e:
            print(f"   âš ï¸ t-SNEå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        
        # UMAP
        try:
            umap_embedding = alt_dim.try_umap()
            if umap_embedding is not None:
                self.dimensionality_results['UMAP'] = alt_dim.results['UMAP']
                
                # ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—è©•ä¾¡
                evaluator = DimensionalityReductionEvaluator(
                    umap_embedding,
                    self.best_clustering_labels
                )
                self.dim_evaluation_results['UMAP'] = evaluator.evaluate_overlap()
        except Exception as e:
            print(f"   âš ï¸ UMAPå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
    
    def _select_best_dimensionality_reduction(self):
        """æœ€é©ãªæ¬¡å…ƒå‰Šæ¸›æ‰‹æ³•ã‚’é¸æŠ"""
        print("\n" + "="*70)
        print("ğŸ† æ¬¡å…ƒå‰Šæ¸›æ‰‹æ³•ã®æ¯”è¼ƒ")
        print("="*70)
        
        best_method = 'PCA'
        best_score = self.dim_evaluation_results.get('PCA', {}).get('overlap', float('inf'))
        
        print(f"\næ‰‹æ³• | ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—ã‚¹ã‚³ã‚¢ (ä½â†“)")
        print("-" * 70)
        
        for method, scores in self.dim_evaluation_results.items():
            overlap = scores.get('overlap', float('inf'))
            marker = "ğŸ¥‡" if overlap < best_score else "  "
            print(f"{marker} {method:10s} | {overlap:.4f}")
            
            if overlap < best_score:
                best_score = overlap
                best_method = method
        
        self.best_dim_reduction_method = best_method
        self.best_dim_reduction_embedding = self.dimensionality_results[best_method]['embedding']
        
        print(f"\nğŸ¯ é¸æŠã•ã‚ŒãŸæ‰‹æ³•: {best_method} (ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—: {best_score:.4f})")
        self._log(f"ğŸ¯ æ¬¡å…ƒå‰Šæ¸›æ‰‹æ³•: {best_method}")
    
    def _print_summary(self):
        """çµæœã®ã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º"""
        print("\n" + "="*70)
        print("ğŸ“‹ Agenticã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚° æœ€çµ‚çµæœ")
        print("="*70)
        
        print(f"\nğŸ¯ æœ€é©ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°æ‰‹æ³•: {self.best_clustering_method}")
        if self.best_clustering_method in self.evaluation_results:
            scores = self.evaluation_results[self.best_clustering_method]
            print(f"   ç·åˆã‚¹ã‚³ã‚¢: {scores['overall']:.2f}/100")
            print(f"   ã‚·ãƒ«ã‚¨ãƒƒãƒˆã‚¹ã‚³ã‚¢: {scores['silhouette']:.4f}")
        
        print(f"\nğŸ¯ æœ€é©æ¬¡å…ƒå‰Šæ¸›æ‰‹æ³•: {self.best_dim_reduction_method}")
        if self.best_dim_reduction_method in self.dim_evaluation_results:
            scores = self.dim_evaluation_results[self.best_dim_reduction_method]
            print(f"   ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—ã‚¹ã‚³ã‚¢: {scores['overlap']:.4f}")
        
        print(f"\nğŸ“ æ”¹å–„å±¥æ­´:")
        for i, log in enumerate(self.improvement_log, 1):
            print(f"   {i}. {log}")
    
    def _log(self, message):
        """æ”¹å–„ãƒ­ã‚°ã‚’è¨˜éŒ²"""
        print(f"\n{'='*70}")
        print(message)
        print('='*70)
        self.improvement_log.append(message)
    
    def _prepare_final_results(self):
        """æœ€çµ‚çµæœã‚’æº–å‚™"""
        df_result = self.df.copy()
        df_result['cluster'] = self.best_clustering_labels
        
        # ã‚¯ãƒ©ã‚¹ã‚¿ã‚µãƒãƒªãƒ¼
        cluster_summary = df_result.groupby('cluster')[self.feature_cols].mean()
        
        return {
            'df_with_cluster': df_result,
            'cluster_summary': cluster_summary,
            'embedding': self.best_dim_reduction_embedding,
            'labels': self.best_clustering_labels,
            'clustering_method': self.best_clustering_method,
            'dim_reduction_method': self.best_dim_reduction_method,
            'evaluation_scores': self.evaluation_results.get(self.best_clustering_method, {}),
            'improvement_log': self.improvement_log
        }
