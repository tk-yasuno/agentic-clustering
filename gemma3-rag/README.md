# Gemma3 RAG KasenSabo MVP

æ²³å·ãƒ»ãƒ€ãƒ ãƒ»ç ‚é˜²ã®æŠ€è¡“åŸºæº–ã‚’å¯¾è±¡ã¨ã—ãŸ **Gemma 3ï¼ˆINT4/INT8ï¼‰+ Ollama** ã«ã‚ˆã‚‹RAGãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚·ã‚¹ãƒ†ãƒ 

## ğŸ“‹ æ¦‚è¦

ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯ã€å›½åœŸäº¤é€šçœã®æ²³å·ãƒ»ãƒ€ãƒ ãƒ»ç ‚é˜²æŠ€è¡“åŸºæº–ã‚’ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã¨ã—ã¦ã€Gemma 3ãƒ¢ãƒ‡ãƒ«ï¼ˆé‡å­åŒ–INT4/INT8ï¼‰ã‚’ä½¿ç”¨ã—ãŸRAGï¼ˆRetrieval-Augmented Generationï¼‰ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯è©•ä¾¡ã‚’è¡Œã„ã¾ã™ã€‚

### ä¸»ãªç‰¹å¾´

- **çŸ¥è­˜ãƒ™ãƒ¼ã‚¹**: æ²³å·ãƒ»ãƒ€ãƒ ãƒ»ç ‚é˜²ã®æŠ€è¡“åŸºæº–ï¼ˆMarkdownå½¢å¼ã€8ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆï¼‰
- **LLMãƒ¢ãƒ‡ãƒ«**: Gemma 3 (2B) - INT4/INT8é‡å­åŒ–ç‰ˆï¼ˆOllamaï¼‰
- **ãƒ™ã‚¯ãƒˆãƒ«DB**: FAISSï¼ˆé«˜é€Ÿé¡ä¼¼åº¦æ¤œç´¢ï¼‰
- **åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«**: intfloat/multilingual-e5-baseï¼ˆ768æ¬¡å…ƒã€æ—¥æœ¬èªå¯¾å¿œï¼‰
- **ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯**: 200å•ã®æŠ€è¡“çš„è³ªå•
- **è©•ä¾¡æŒ‡æ¨™**: EMã€F1ã€BLEUã€ROUGEã€å¿œç­”æ™‚é–“ã€ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡
- **GPUå¯¾å¿œ**: NVIDIA RTX 4060 Tiï¼ˆCUDA 12.9ï¼‰ã§é«˜é€Ÿæ¨è«–

## ğŸ—ï¸ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ 

```
gemma3-rag/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ kasensabo_knowledge_base/     # æŠ€è¡“åŸºæº–ãƒ‡ãƒ¼ã‚¿ï¼ˆMarkdownï¼‰
â”‚       â”œâ”€â”€ 00_training_overview_2025.md
â”‚       â”œâ”€â”€ 01_training_chousa_2025.md
â”‚       â”œâ”€â”€ 02_training_keikaku_kihon_2025.md
â”‚       â”œâ”€â”€ 03_training_keikaku_shisetsu_2025.md
â”‚       â”œâ”€â”€ 04_training_sekkei_2025.md
â”‚       â”œâ”€â”€ 05_training_ijikanri_kasen_2025.md
â”‚       â”œâ”€â”€ 06_training_ijikanri_dam_2025.md
â”‚       â””â”€â”€ 07_training_ijikanri_sabo_2025.md
â”œâ”€â”€ questions/
â”‚   â””â”€â”€ bench_questions_200.json      # ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯è³ªå•ï¼ˆ200å•ï¼‰
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ build_index.py                # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ§‹ç¯‰
â”‚   â”œâ”€â”€ run_rag.py                    # RAGå®Ÿè¡Œ
â”‚   â”œâ”€â”€ evaluate.py                   # è©•ä¾¡æŒ‡æ¨™è¨ˆç®—
â”‚   â””â”€â”€ run_benchmark.py              # ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ
â”œâ”€â”€ index/
â”‚   â””â”€â”€ faiss_index/                  # FAISSã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼ˆç”Ÿæˆã•ã‚Œã‚‹ï¼‰
â”œâ”€â”€ results/                          # ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœï¼ˆç”Ÿæˆã•ã‚Œã‚‹ï¼‰
â”œâ”€â”€ config.yaml                       # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«
â”œâ”€â”€ requirements.txt                  # Pythonä¾å­˜é–¢ä¿‚
â””â”€â”€ README.md                         # ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«
```

## ğŸš€ ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

### 1. å‰ææ¡ä»¶

- Python 3.12ä»¥ä¸Š
- Ollama 0.12.11ä»¥ä¸Šï¼ˆã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ¸ˆã¿ï¼‰
- 16GBä»¥ä¸Šã®RAMæ¨å¥¨
- ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰NVIDIA GPUï¼ˆCUDAå¯¾å¿œï¼‰ã§GPUæ¨è«–ãŒå¯èƒ½

### 2. Ollamaã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã¨è¨­å®š

```bash
# Ollamaã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼ˆWindowsï¼‰
# https://ollama.ai/ ã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰

# Gemma 3ãƒ¢ãƒ‡ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
ollama pull gemma:2b-instruct-q4_K_M
ollama pull gemma:2b-instruct-q8_0
```

### 3. Pythonç’°å¢ƒã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

```powershell
# ä¾å­˜ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pip install -r requirements.txt

# NLTKãƒ‡ãƒ¼ã‚¿ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
python -c "import nltk; nltk.download('punkt'); nltk.download('punkt_tab')"
```

**ä¸»è¦ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸:**
- llama-index-core 0.3.79
- llama-index-llms-ollama
- llama-index-embeddings-huggingface
- faiss-cpuï¼ˆãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ï¼‰
- transformersã€sentence-transformersï¼ˆåŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ï¼‰
- scikit-learnã€nltkã€rouge-scoreï¼ˆè©•ä¾¡æŒ‡æ¨™ï¼‰

### 4. Ollamaã‚µãƒ¼ãƒ“ã‚¹ã®èµ·å‹•

```powershell
# åˆ¥ã®ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§Ollamaã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•
ollama serve

# GPUä½¿ç”¨ç¢ºèªï¼ˆNVIDIA GPUã®å ´åˆï¼‰
nvidia-smi
```

**GPUè¨­å®šç¢ºèª:**
- OllamaãŒè‡ªå‹•çš„ã«GPUã‚’æ¤œå‡ºï¼ˆCUDAå¯¾å¿œï¼‰
- ãƒ­ã‚°ã« "inference compute" ã¨ GPUåãŒè¡¨ç¤ºã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
- GPUãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: INT4ã§ç´„2.5GBã€INT8ã§ç´„3-4GB

### 5. ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®æ§‹ç¯‰

```powershell
# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã§å®Ÿè¡Œ
python scripts/build_index.py
```

**å®Ÿè¡Œå†…å®¹:**
- `data/kasensabo_knowledge_base/`å†…ã®8ã¤ã®Markdownãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
- ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²ï¼ˆã‚µã‚¤ã‚º512ã€ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—50ï¼‰
- multilingual-e5-baseã§åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ç”Ÿæˆï¼ˆ768æ¬¡å…ƒï¼‰
- FAISSã«ä¿å­˜ï¼ˆ`index/faiss_index/`ï¼‰
- ç´„6,471ãƒãƒ£ãƒ³ã‚¯ã‚’å‡¦ç†

**æ‰€è¦æ™‚é–“:** ç´„1ã€œ2åˆ†

**å‡ºåŠ›ä¾‹:**
```
==================================================
Gemma3 RAG - Index Building
==================================================

[1] Loading documents from: data/kasensabo_knowledge_base
âœ“ Loaded 8 documents

[2] Initializing embedding model: intfloat/multilingual-e5-base
âœ“ Embedding model loaded
âœ“ Chunk size: 512, Overlap: 50
âœ“ Embedding dimension: 768

[3] Initializing FAISS at: index/faiss_index
âœ“ FAISS initialized

[4] Building vector index...
Generating embeddings: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6471/6471 [01:15<00:00, 85.83it/s]
âœ“ Index built successfully
```

## ğŸ“Š ä½¿ç”¨æ–¹æ³•

### 1. å˜ä¸€ã‚¯ã‚¨ãƒªã®ãƒ†ã‚¹ãƒˆ

```powershell
python scripts/run_rag.py
```

**å®Ÿè¡Œã®æµã‚Œ:**
1. ãƒ¢ãƒ‡ãƒ«é¸æŠï¼ˆINT4ã¾ãŸã¯INT8ï¼‰
2. 3ã¤ã®ãƒ†ã‚¹ãƒˆè³ªå•ã§å‹•ä½œç¢ºèª
3. å¿œç­”æ™‚é–“ã¨ã‚½ãƒ¼ã‚¹ãƒãƒ¼ãƒ‰æ•°ã‚’è¡¨ç¤º

**å‡ºåŠ›ä¾‹:**
```
==================================================
Gemma3 RAG - Query Execution Demo
==================================================

Available models:
1. gemma:2b-instruct-q4_K_M (INT4)
2. gemma:2b-instruct-q8_0 (INT8)

Select model (1 or 2): 2

Initializing RAG system with gemma:2b-instruct-q8_0...
âœ“ Embedding model initialized: intfloat/multilingual-e5-base
âœ“ Index loaded from: index/faiss_index
âœ“ Query engine created with model: gemma:2b-instruct-q8_0

==================================================
Running test queries...
==================================================

[Query 1] æ²³å·ã®è¨ˆç”»é«˜æ°´æµé‡ã¨ã¯ä½•ã§ã™ã‹ï¼Ÿ
Response time: 1.35s
Response: è¨ˆç”»é«˜æ°´æµé‡ã¨ã¯ã€æ²³å·è¨ˆç”»ã«ãŠã„ã¦è¨­å®šã•ã‚Œã‚‹...
Source nodes: 3

[Query 2] ãƒ€ãƒ ã®æ´ªæ°´èª¿ç¯€æ–¹å¼ã«ã¤ã„ã¦æ•™ãˆã¦ãã ã•ã„ã€‚
Response time: 1.01s
Response: ãƒ€ãƒ ã«ã‚ˆã‚‹æ´ªæ°´èª¿ç¯€æ–¹å¼ã¯ã€æ´ªæ°´æµå‡ºã®ç‰¹æ€§ã€èª¿ç¯€åŠ¹ç‡...
Source nodes: 3
```

**ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ:**
- æ—¥æœ¬èªã§å›ç­”ã™ã‚‹ã‚ˆã†ã«è¨­å®šæ¸ˆã¿
- æ²³å·ãƒ»ãƒ€ãƒ ãƒ»ç ‚é˜²æŠ€è¡“ã®å°‚é–€å®¶ã¨ã—ã¦å¿œç­”
- ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ã«åŸºã¥ã„ãŸæ­£ç¢ºãªå›ç­”ã‚’ç”Ÿæˆ

### 2. ãƒ•ãƒ«ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®å®Ÿè¡Œ

```powershell
python scripts/run_benchmark.py
```

**å®Ÿè¡Œå†…å®¹:**
1. `questions/bench_questions_200.json`ã‹ã‚‰200å•ã‚’èª­ã¿è¾¼ã¿
2. INT4ãƒ¢ãƒ‡ãƒ«ï¼ˆgemma:2b-instruct-q4_K_Mï¼‰ã§å…¨è³ªå•ã‚’å®Ÿè¡Œ
3. INT8ãƒ¢ãƒ‡ãƒ«ï¼ˆgemma:2b-instruct-q8_0ï¼‰ã§å…¨è³ªå•ã‚’å®Ÿè¡Œ
4. è©•ä¾¡æŒ‡æ¨™ã‚’è¨ˆç®—ï¼ˆEMã€F1ã€BLEUã€ROUGEï¼‰
5. çµæœã‚’`results/`ã«ä¿å­˜

**æ‰€è¦æ™‚é–“:** ç´„15ã€œ30åˆ†ï¼ˆGPUä½¿ç”¨æ™‚ï¼‰

**ç”Ÿæˆãƒ•ã‚¡ã‚¤ãƒ«:**
- `results/benchmark_results_INT4.json` - INT4ãƒ¢ãƒ‡ãƒ«ã®å…¨çµæœ
- `results/benchmark_results_INT8.json` - INT8ãƒ¢ãƒ‡ãƒ«ã®å…¨çµæœ
- `results/benchmark_comparison.csv` - ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒè¡¨

**ä¸­æ–­ã¨å†é–‹:**
- 50å•ã”ã¨ã«ä¸­é–“çµæœã‚’è‡ªå‹•ä¿å­˜
- Ctrl+Cã§ä¸­æ–­å¯èƒ½
- æ¬¡å›å®Ÿè¡Œæ™‚ã«ç¶šãã‹ã‚‰å†é–‹

### 3. çµæœã®ç¢ºèª

```powershell
# çµæœãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ç¢ºèª
ls results/

# JSONå½¢å¼ã®è©³ç´°çµæœ
# results/benchmark_results_INT4.json
# results/benchmark_results_INT8.json

# CSVå½¢å¼ã®æ¯”è¼ƒçµæœ
# results/benchmark_comparison.csv
```

**æ¯”è¼ƒCSVã®ä¾‹:**
```
Model,EM,F1,BLEU-1,BLEU-2,ROUGE-1,ROUGE-L,Avg_Response_Time,Avg_Memory_MB
INT4,0.15,0.42,0.38,0.22,0.45,0.40,0.85,2541
INT8,0.18,0.48,0.42,0.26,0.49,0.44,1.12,3200
```

## ğŸ¯ è©•ä¾¡æŒ‡æ¨™

### ãƒ†ã‚­ã‚¹ãƒˆè©•ä¾¡

| æŒ‡æ¨™ | èª¬æ˜ |
|------|------|
| **Exact Match (EM)** | å®Œå…¨ä¸€è‡´ç‡ï¼ˆ0 or 1ï¼‰ |
| **F1 Score** | ãƒˆãƒ¼ã‚¯ãƒ³ãƒ¬ãƒ™ãƒ«ã®F1ã‚¹ã‚³ã‚¢ |
| **BLEU-1/2/3/4** | n-gramä¸€è‡´ç‡ |
| **ROUGE-1/2/L** | ãƒªã‚³ãƒ¼ãƒ«é‡è¦–ã®é¡ä¼¼åº¦ |

### ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è©•ä¾¡

| æŒ‡æ¨™ | èª¬æ˜ |
|------|------|
| **Response Time** | ã‚¯ã‚¨ãƒªå¿œç­”æ™‚é–“ï¼ˆç§’ï¼‰ |
| **Memory Usage** | ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ï¼ˆMBï¼‰ |

## ğŸ“ˆ æœŸå¾…ã•ã‚Œã‚‹æ¯”è¼ƒçµæœ

### å®Ÿæ¸¬å€¤ï¼ˆNVIDIA RTX 4060 Tiï¼‰

| é …ç›® | INT4 (q4_K_M) | INT8 (q8_0) |
|------|---------------|-------------|
| **å¿œç­”æ™‚é–“ï¼ˆåˆå›ï¼‰** | 5.20ç§’ | 4.86ç§’ |
| **å¿œç­”æ™‚é–“ï¼ˆ2å›ç›®ä»¥é™ï¼‰** | 0.84-1.12ç§’ | 0.67-1.01ç§’ |
| **GPUãƒ¡ãƒ¢ãƒªä½¿ç”¨** | ç´„2.5GB | ç´„3-4GB |
| **æ—¥æœ¬èªå›ç­”å“è³ª** | è‰¯å¥½ | è‰¯å¥½ã€œå„ªç§€ |

### äºˆæƒ³ã•ã‚Œã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœ

| é …ç›® | INT4 (q4_K_M) | INT8 (q8_0) | å‚™è€ƒ |
|------|---------------|-------------|------|
| **å¿œç­”é€Ÿåº¦** | â— é«˜é€Ÿï¼ˆ0.84-1.12ç§’ï¼‰ | â— é«˜é€Ÿï¼ˆ0.67-1.01ç§’ï¼‰ | GPUä½¿ç”¨æ™‚ |
| **GPUãƒ¡ãƒ¢ãƒª** | â— å°‘ï¼ˆ2.5GBï¼‰ | â—¯ ä¸­ï¼ˆ3-4GBï¼‰ | RTX 4060 Ti |
| **å¿œç­”ç²¾åº¦** | â—¯ è‰¯å¥½ | â—¯ è‰¯å¥½ã€œå„ªç§€ | INT8ã®æ–¹ãŒã‚„ã‚„é«˜ç²¾åº¦ |
| **F1ã‚¹ã‚³ã‚¢** | 0.40ã€œ0.50ï¼ˆæ¨å®šï¼‰ | 0.45ã€œ0.55ï¼ˆæ¨å®šï¼‰ | æŠ€è¡“æ–‡æ›¸ç‰¹æœ‰ã®é›£æ˜“åº¦ |
| **é©ç”¨å ´é¢** | é«˜é€Ÿå¿œç­”é‡è¦–ã€ãƒ¡ãƒ¢ãƒªåˆ¶ç´„ | ç²¾åº¦é‡è¦–ã€ãƒãƒ©ãƒ³ã‚¹å‹ |

**ç‰¹å¾´:**
- INT4: ã‚ˆã‚Šé«˜é€Ÿã§ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ãŒè‰¯ã„ï¼ˆGPUæ¨è«–ã§1ç§’ä»¥ä¸‹ã‚‚å¯èƒ½ï¼‰
- INT8: ç²¾åº¦ã¨é€Ÿåº¦ã®ãƒãƒ©ãƒ³ã‚¹ãŒè‰¯ã„ï¼ˆæ¨å¥¨ï¼‰
- ä¸¡ãƒ¢ãƒ‡ãƒ«ã¨ã‚‚GPUæ¨è«–ã§å®Ÿç”¨çš„ãªé€Ÿåº¦ã‚’é”æˆ

## âš™ï¸ è¨­å®šã®ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚º

`config.yaml`ã‚’ç·¨é›†ã—ã¦ã€ä»¥ä¸‹ã‚’ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã§ãã¾ã™ï¼š

```yaml
# åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã®å¤‰æ›´
embedding:
  model_name: "intfloat/multilingual-e5-base"  # 1.1GBã€768æ¬¡å…ƒ
  # model_name: "intfloat/multilingual-e5-large"  # 2.5GBã€1024æ¬¡å…ƒï¼ˆé«˜ç²¾åº¦ï¼‰
  # model_name: "intfloat/multilingual-e5-small"  # 470MBã€384æ¬¡å…ƒï¼ˆè»½é‡ï¼‰
  device: "cuda"  # GPUã‚’ä½¿ç”¨ã™ã‚‹å ´åˆã¯ "cuda"ã€CPUã®å ´åˆã¯ "cpu"

# ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºã®èª¿æ•´
index:
  chunk_size: 512  # å¤§ããã™ã‚‹ã¨æ–‡è„ˆãŒåºƒãŒã‚‹ãŒå‡¦ç†ãŒé‡ããªã‚‹
  chunk_overlap: 50  # ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—ã‚’å¢—ã‚„ã™ã¨å¢ƒç•Œã§ã®æƒ…å ±æå¤±ãŒæ¸›ã‚‹

# RAGãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
rag:
  temperature: 0.1  # ä½ã„ã»ã©æ±ºå®šçš„ã€é«˜ã„ã»ã©å‰µé€ çš„
  similarity_top_k: 3  # é¡ä¼¼ãƒãƒ£ãƒ³ã‚¯ã®å–å¾—æ•°ï¼ˆ1-5æ¨å¥¨ï¼‰

# ãƒ¢ãƒ‡ãƒ«ã®è¿½åŠ ãƒ»å¤‰æ›´
models:
  - name: "gemma:2b-instruct-q4_K_M"
    quantization: "INT4"
  - name: "gemma:2b-instruct-q8_0"
    quantization: "INT8"
  # ä»–ã®ãƒ¢ãƒ‡ãƒ«ã‚’è©¦ã™å ´åˆ:
  # - name: "gemma:7b-instruct-q4_K_M"
  #   quantization: "INT4"
```

## ğŸ› ï¸ ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### 1. Ollamaã«æ¥ç¶šã§ããªã„

```powershell
# Ollamaã‚µãƒ¼ãƒ“ã‚¹ã®èµ·å‹•ç¢ºèª
ollama list

# ãƒ¢ãƒ‡ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèª
ollama run gemma:2b-instruct-q4_K_M "Hello"

# Ollamaã‚µãƒ¼ãƒ“ã‚¹ã‚’æ‰‹å‹•èµ·å‹•
ollama serve
```

### 2. GPUãŒèªè­˜ã•ã‚Œãªã„

```powershell
# NVIDIA GPUç¢ºèª
nvidia-smi

# Ollamaã®ãƒ­ã‚°ã‚’ç¢ºèªï¼ˆGPUæ¤œå‡ºãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ç¢ºèªï¼‰
# "inference compute" ã§GPUæƒ…å ±ãŒè¡¨ç¤ºã•ã‚Œã‚‹ã¯ãš
```

**å¯¾å‡¦æ³•:**
- CUDAãƒ‰ãƒ©ã‚¤ãƒãƒ¼ã‚’æœ€æ–°ç‰ˆã«æ›´æ–°
- Ollamaã‚’å†èµ·å‹•ã—ã¦è‡ªå‹•æ¤œå‡ºã•ã›ã‚‹

### 3. FAISSã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒè¦‹ã¤ã‹ã‚‰ãªã„

```powershell
# ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å†æ§‹ç¯‰
python scripts/build_index.py
```

## ğŸ“ è³ªå•ãƒ‡ãƒ¼ã‚¿ã®å½¢å¼

`questions/bench_questions_200.json`ã®å½¢å¼ä¾‹ï¼š

```json
[
  {
    "id": 1,
    "question": "æ²³å·ã®è¨ˆç”»é«˜æ°´æµé‡ã¨ã¯ä½•ã§ã™ã‹ï¼Ÿ",
    "answer": "åŸºæœ¬é«˜æ°´ã®ãƒ”ãƒ¼ã‚¯æµé‡ã‹ã‚‰æ´ªæ°´èª¿ç¯€æ–½è¨­ã«ã‚ˆã‚‹èª¿ç¯€æµé‡ã‚’å·®ã—å¼•ã„ãŸã‚‚ã®",
    "category": "æ²³å·è¨ˆç”»"
  },
  ...
]
```

## ğŸ”¬ ã‚«ã‚¹ã‚¿ãƒ è©•ä¾¡ã®è¿½åŠ 

`scripts/evaluate.py`ã‚’æ‹¡å¼µã—ã¦ã€ç‹¬è‡ªã®è©•ä¾¡æŒ‡æ¨™ã‚’è¿½åŠ ã§ãã¾ã™ï¼š

```python
class RAGEvaluator:
    def custom_metric(self, prediction: str, reference: str) -> float:
        # ã‚«ã‚¹ã‚¿ãƒ è©•ä¾¡ãƒ­ã‚¸ãƒƒã‚¯
        pass
```

## ï¿½ æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯è©³ç´°

### ã‚³ã‚¢æŠ€è¡“
- **LLM**: Gemma 3 (2B) - Googleé–‹ç™ºã®ã‚ªãƒ¼ãƒ—ãƒ³LLM
- **é‡å­åŒ–**: INT4 (q4_K_M) / INT8 (q8_0) - ãƒ¢ãƒ‡ãƒ«åœ§ç¸®
- **æ¨è«–ã‚¨ãƒ³ã‚¸ãƒ³**: Ollama 0.12.11 - ãƒ­ãƒ¼ã‚«ãƒ«LLMå®Ÿè¡Œç’°å¢ƒ
- **RAGãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯**: LlamaIndex 0.3.79 - RAGãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æ§‹ç¯‰
- **ãƒ™ã‚¯ãƒˆãƒ«DB**: FAISS - Facebook AIé–‹ç™ºã®é«˜é€Ÿé¡ä¼¼åº¦æ¤œç´¢
- **åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«**: multilingual-e5-base - å¤šè¨€èªå¯¾å¿œï¼ˆ768æ¬¡å…ƒï¼‰

### ä¾å­˜ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸
```
llama-index-core==0.3.79
llama-index-llms-ollama
llama-index-embeddings-huggingface
llama-index-vector-stores-faiss
faiss-cpu
transformers
sentence-transformers
torch
scikit-learn
nltk>=3.9.2
rouge-score
psutil
pyyaml==6.0.2
```

## ï¿½ğŸ“š å‚è€ƒè³‡æ–™

- [Ollamaå…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ](https://ollama.ai/docs)
- [LlamaIndexå…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ](https://docs.llamaindex.ai/)
- [FAISSå…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ](https://github.com/facebookresearch/faiss)
- [Gemma ãƒ¢ãƒ‡ãƒ«æƒ…å ±](https://ai.google.dev/gemma)
- [Multilingual-E5ãƒ¢ãƒ‡ãƒ«](https://huggingface.co/intfloat/multilingual-e5-base)

## ğŸ¤ ã‚³ãƒ³ãƒˆãƒªãƒ“ãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³

- ãƒã‚°å ±å‘Š: Issueä½œæˆ
- æ©Ÿèƒ½ææ¡ˆ: Pull Requestæ­“è¿
- ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœã®å…±æœ‰: Discussionã§å…±æœ‰

## ğŸ“„ ãƒ©ã‚¤ã‚»ãƒ³ã‚¹

MIT License

## ğŸ‘¥ ä½œæˆè€…

LangChain Learning Project - Gemma3 RAG Team

---

## ğŸ“ å®Ÿè£…çŠ¶æ³ã¨æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

### âœ… å®Œäº†ã—ãŸå®Ÿè£…

1. **ç’°å¢ƒæ§‹ç¯‰**: Python 3.12ã€Ollamaã€ä¾å­˜ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸
2. **ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ§‹ç¯‰**: FAISS + multilingual-e5-baseï¼ˆ768æ¬¡å…ƒï¼‰
3. **RAGã‚·ã‚¹ãƒ†ãƒ **: æ—¥æœ¬èªå¯¾å¿œã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä»˜ã
4. **GPUæ¨è«–**: NVIDIA RTX 4060 Tiä¸Šã§é«˜é€Ÿæ¨è«–ç¢ºèª
5. **å‹•ä½œç¢ºèª**: INT4/INT8ä¸¡ãƒ¢ãƒ‡ãƒ«ã§ãƒ†ã‚¹ãƒˆæˆåŠŸ

### ğŸ”„ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

1. **ãƒ•ãƒ«ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ**: 200å•ã§ INT4 vs INT8ã®è©³ç´°æ¯”è¼ƒ
2. **çµæœåˆ†æ**: ã‚«ãƒ†ã‚´ãƒªåˆ¥ï¼ˆæ²³å·/ãƒ€ãƒ /ç ‚é˜²ï¼‰ã®ç²¾åº¦åˆ†æ
3. **ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°**: temperatureã€top_kã€chunk_sizeã®æœ€é©åŒ–
4. **åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒ**: base vs large ã§ã®ç²¾åº¦å·®æ¤œè¨¼
5. **ãƒ¬ãƒãƒ¼ãƒˆä½œæˆ**: ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœã®å¯è¦–åŒ–ã¨è€ƒå¯Ÿ
4. ğŸš€ **æœ¬ç•ªå±•é–‹**: APIåŒ–ã€Webã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹è¿½åŠ 

---

**è³ªå•ã‚„å•é¡ŒãŒã‚ã‚Šã¾ã—ãŸã‚‰ã€Issueã‚’ä½œæˆã—ã¦ãã ã•ã„ï¼**
