# Gemma3 RAG KasenSabo MVP - ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‚¬ã‚¤ãƒ‰

## ğŸ¯ ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆï¼ˆ10åˆ†ã§å§‹ã‚ã‚‹ï¼‰

### ã‚¹ãƒ†ãƒƒãƒ—1: Ollamaæº–å‚™ï¼ˆ5åˆ†ï¼‰

```powershell
# 1. OllamaãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
ollama --version

# 2. Gemma 3ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆå„1-2åˆ†ï¼‰
ollama pull gemma:2b-instruct-q4_K_M
ollama pull gemma:2b-instruct-q8_0

# 3. å‹•ä½œç¢ºèª
ollama run gemma:2b-instruct-q4_K_M "ã“ã‚“ã«ã¡ã¯"
# Ctrl+Dã§çµ‚äº†
```

### ã‚¹ãƒ†ãƒƒãƒ—2: Pythonç’°å¢ƒï¼ˆ3åˆ†ï¼‰

```powershell
# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ç§»å‹•
cd C:\Users\yasun\LangChain\learning-langchain\gemma3-rag

# ä»®æƒ³ç’°å¢ƒä½œæˆ
python -m venv venv

# ä»®æƒ³ç’°å¢ƒã‚’ã‚¢ã‚¯ãƒ†ã‚£ãƒ™ãƒ¼ãƒˆ
.\venv\Scripts\Activate.ps1

# ä¾å­˜ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pip install -r requirements.txt

# NLTKãƒ‡ãƒ¼ã‚¿ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
python -c "import nltk; nltk.download('punkt')"
```

### ã‚¹ãƒ†ãƒƒãƒ—3: ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ§‹ç¯‰ï¼ˆ5-10åˆ†ï¼‰

```powershell
# ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æ§‹ç¯‰
python scripts/build_index.py

# âœ“ Loaded XX documents ã¨è¡¨ç¤ºã•ã‚Œã‚Œã°OK
```

### ã‚¹ãƒ†ãƒƒãƒ—4: å‹•ä½œç¢ºèªï¼ˆ1åˆ†ï¼‰

```powershell
# ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
python scripts/run_rag.py

# ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠï¼ˆ1: INT4, 2: INT8ï¼‰
# 3ã¤ã®ãƒ†ã‚¹ãƒˆè³ªå•ã§å‹•ä½œç¢ºèª
```

---

## ğŸ“‹ è©³ç´°ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—æ‰‹é †

### A. ã‚·ã‚¹ãƒ†ãƒ è¦ä»¶

#### å¿…é ˆè¦ä»¶
- **OS**: Windows 10/11, macOS, Linux
- **Python**: 3.9ä»¥ä¸Šï¼ˆæ¨å¥¨: 3.10 or 3.11ï¼‰
- **RAM**: æœ€ä½8GBï¼ˆæ¨å¥¨: 16GBä»¥ä¸Šï¼‰
- **ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸**: 10GBä»¥ä¸Šã®ç©ºãå®¹é‡

#### æ¨å¥¨è¦ä»¶
- **GPU**: å¿…é ˆã§ã¯ãªã„ãŒã€ã‚ã‚‹ã¨é«˜é€ŸåŒ–
- **CPU**: 4ã‚³ã‚¢ä»¥ä¸Š

### B. Ollamaã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

#### Windows

```powershell
# å…¬å¼ã‚µã‚¤ãƒˆã‹ã‚‰ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ©ãƒ¼ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
# https://ollama.ai/download

# ã¾ãŸã¯ã€wingetã‚’ä½¿ç”¨
winget install Ollama.Ollama

# ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å¾Œã€PowerShellã§ç¢ºèª
ollama --version
```

#### macOS

```bash
# Homebrewã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
brew install ollama

# ã¾ãŸã¯å…¬å¼ã‚µã‚¤ãƒˆã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
# https://ollama.ai/download
```

#### Linux

```bash
# ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å®Ÿè¡Œ
curl -fsSL https://ollama.ai/install.sh | sh
```

### C. Gemma 3ãƒ¢ãƒ‡ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰

```powershell
# INT4ãƒ¢ãƒ‡ãƒ«ï¼ˆç´„1.5GBï¼‰
ollama pull gemma:2b-instruct-q4_K_M

# INT8ãƒ¢ãƒ‡ãƒ«ï¼ˆç´„2.5GBï¼‰
ollama pull gemma:2b-instruct-q8_0

# ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®ç¢ºèª
ollama list

# å‡ºåŠ›ä¾‹:
# NAME                           ID              SIZE      MODIFIED
# gemma:2b-instruct-q4_K_M      abc123def...    1.5 GB    2 minutes ago
# gemma:2b-instruct-q8_0        def456ghi...    2.5 GB    1 minute ago
```

### D. Pythonç’°å¢ƒã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

#### 1. ä»®æƒ³ç’°å¢ƒã®ä½œæˆ

```powershell
# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã§å®Ÿè¡Œ
cd C:\Users\yasun\LangChain\learning-langchain\gemma3-rag

# ä»®æƒ³ç’°å¢ƒã‚’ä½œæˆ
python -m venv venv

# ã‚¢ã‚¯ãƒ†ã‚£ãƒ™ãƒ¼ãƒˆï¼ˆWindows PowerShellï¼‰
.\venv\Scripts\Activate.ps1

# ã‚¢ã‚¯ãƒ†ã‚£ãƒ™ãƒ¼ãƒˆï¼ˆWindows CMDï¼‰
.\venv\Scripts\activate.bat

# ã‚¢ã‚¯ãƒ†ã‚£ãƒ™ãƒ¼ãƒˆï¼ˆLinux/macOSï¼‰
source venv/bin/activate

# (venv) ãŒè¡¨ç¤ºã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
```

#### 2. ä¾å­˜ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

```powershell
# pip ã®ã‚¢ãƒƒãƒ—ã‚°ãƒ¬ãƒ¼ãƒ‰
python -m pip install --upgrade pip

# ä¾å­˜ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pip install -r requirements.txt

# ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ç¢ºèª
pip list | Select-String "llama-index|chromadb|ollama"
```

#### 3. NLTKãƒ‡ãƒ¼ã‚¿ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰

```powershell
# å¯¾è©±çš„ã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
python -c "import nltk; nltk.download('punkt')"

# ã¾ãŸã¯ã€Pythonã‚¹ã‚¯ãƒªãƒ—ãƒˆå†…ã§
python -c "
import nltk
nltk.download('punkt', quiet=True)
nltk.download('punkt_tab', quiet=True)
print('âœ“ NLTK data downloaded')
"
```

### E. ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™ç¢ºèª

```powershell
# çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã®ç¢ºèª
ls data/kasensabo_knowledge_base/

# å‡ºåŠ›ä¾‹:
# 00_training_overview_2025.md
# 01_training_chousa_2025.md
# ...

# ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯è³ªå•ã®ç¢ºèª
ls questions/

# å‡ºåŠ›ä¾‹:
# bench_questions_200.json
```

### F. ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®æ§‹ç¯‰

```powershell
# ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ§‹ç¯‰ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å®Ÿè¡Œ
python scripts/build_index.py

# å®Ÿè¡Œä¸­ã®è¡¨ç¤ºä¾‹:
# ==================================================
# Gemma3 RAG - Index Building
# ==================================================
# 
# [1] Loading documents from: data/kasensabo_knowledge_base
# âœ“ Loaded 8 documents
# 
# [2] Initializing embedding model: intfloat/multilingual-e5-large
# âœ“ Embedding model loaded
# âœ“ Chunk size: 512, Overlap: 50
# 
# [3] Initializing ChromaDB at: index/chroma_index
# âœ“ ChromaDB initialized
# 
# [4] Building vector index...
# [é€²è¡ŒçŠ¶æ³ãƒãƒ¼]
# âœ“ Index built successfully
# 
# ==================================================
# âœ… Index building completed successfully!
```

**æ‰€è¦æ™‚é–“**: 5ã€œ10åˆ†ï¼ˆãƒ‡ãƒ¼ã‚¿é‡ã¨ãƒã‚·ãƒ³æ€§èƒ½ã«ã‚ˆã‚‹ï¼‰

**ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°**:
- ãƒ¡ãƒ¢ãƒªä¸è¶³ã‚¨ãƒ©ãƒ¼ â†’ `config.yaml`ã®`chunk_size`ã‚’256ã«æ¸›ã‚‰ã™
- ChromaDBã‚¨ãƒ©ãƒ¼ â†’ `index/`ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å‰Šé™¤ã—ã¦å†å®Ÿè¡Œ

---

## ğŸ§ª å‹•ä½œç¢ºèª

### 1. å˜ä¸€ã‚¯ã‚¨ãƒªãƒ†ã‚¹ãƒˆ

```powershell
# RAGå®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’èµ·å‹•
python scripts/run_rag.py

# ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«å¾“ã£ã¦æ“ä½œ:
# Available models:
# 1. gemma:2b-instruct-q4_K_M (INT4)
# 2. gemma:2b-instruct-q8_0 (INT8)
# 
# Select model (1 or 2): 1
# 
# Initializing RAG system with gemma:2b-instruct-q4_K_M...
# âœ“ Embedding model initialized: intfloat/multilingual-e5-large
# âœ“ Index loaded from: index/chroma_index
# âœ“ Query engine created with model: gemma:2b-instruct-q4_K_M
# 
# Running test queries...
# [Query 1] æ²³å·ã®è¨ˆç”»é«˜æ°´æµé‡ã¨ã¯ä½•ã§ã™ã‹ï¼Ÿ
# Response time: 2.34s
# Response: è¨ˆç”»é«˜æ°´æµé‡ã¯...
```

### 2. è©•ä¾¡æ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆ

```powershell
# è©•ä¾¡ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®ãƒ‡ãƒ¢ã‚’å®Ÿè¡Œ
python scripts/evaluate.py

# å‡ºåŠ›ä¾‹:
# ==================================================
# RAG Evaluator Demo
# ==================================================
# 
# [Individual Evaluations]
# Case 1:
#   exact_match: 0
#   f1_score: 0.7500
#   bleu_1: 0.6234
#   rouge1_f: 0.7123
#   response_time: 2.5000
```

---

## ğŸš€ æœ¬æ ¼å®Ÿè¡Œ

### ãƒ•ãƒ«ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®å®Ÿè¡Œ

```powershell
# ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å®Ÿè¡Œ
python scripts/run_benchmark.py

# å®Ÿè¡Œæ™‚é–“: ç´„30ã€œ60åˆ†
```

**å®Ÿè¡Œå†…å®¹**:
1. 200å•ã®è³ªå•ã‚’èª­ã¿è¾¼ã¿
2. INT4ãƒ¢ãƒ‡ãƒ«ã§å…¨è³ªå•ã‚’å®Ÿè¡Œï¼ˆç´„15-30åˆ†ï¼‰
3. INT8ãƒ¢ãƒ‡ãƒ«ã§å…¨è³ªå•ã‚’å®Ÿè¡Œï¼ˆç´„15-30åˆ†ï¼‰
4. è©•ä¾¡æŒ‡æ¨™ã‚’è¨ˆç®—
5. çµæœã‚’JSON/CSVå½¢å¼ã§ä¿å­˜
6. ãƒ¢ãƒ‡ãƒ«é–“ã®æ¯”è¼ƒè¡¨ã‚’ç”Ÿæˆ

**çµæœã®ä¿å­˜å…ˆ**:
- `results/gemma_2b-instruct-q4_K_M_benchmark_*.json`
- `results/gemma_2b-instruct-q8_0_benchmark_*.json`
- `results/model_comparison_*.csv`

---

## ğŸ”§ ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### ã‚¨ãƒ©ãƒ¼åˆ¥å¯¾å‡¦æ³•

#### 1. `ModuleNotFoundError: No module named 'XXX'`

```powershell
# ä»®æƒ³ç’°å¢ƒãŒã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‹ç¢ºèª
# ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã« (venv) ãŒè¡¨ç¤ºã•ã‚Œã¦ã„ã‚‹ã‹ï¼Ÿ

# ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’å†ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pip install -r requirements.txt --force-reinstall
```

#### 2. `ollama.ConnectionError: Could not connect to Ollama`

```powershell
# Ollamaã‚µãƒ¼ãƒ“ã‚¹ãŒèµ·å‹•ã—ã¦ã„ã‚‹ã‹ç¢ºèª
ollama list

# ã‚¨ãƒ©ãƒ¼ãŒå‡ºã‚‹å ´åˆã€Ollamaã‚’å†èµ·å‹•
# Windows: ã‚¿ã‚¹ã‚¯ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã§Ollamaã‚’çµ‚äº†â†’å†èµ·å‹•
# macOS: Ollamaã‚¢ãƒ—ãƒªã‚’å†èµ·å‹•
```

#### 3. `FileNotFoundError: Index not found`

```powershell
# ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å†æ§‹ç¯‰
python scripts/build_index.py
```

#### 4. ãƒ¡ãƒ¢ãƒªä¸è¶³ã‚¨ãƒ©ãƒ¼

```yaml
# config.yaml ã‚’ç·¨é›†
index:
  chunk_size: 256  # 512 â†’ 256ã«å¤‰æ›´
  chunk_overlap: 25  # 50 â†’ 25ã«å¤‰æ›´

rag:
  similarity_top_k: 2  # 3 â†’ 2ã«å¤‰æ›´
```

#### 5. CUDA/GPUé–¢é€£ã‚¨ãƒ©ãƒ¼

```yaml
# config.yaml ã‚’ç·¨é›†ã—ã¦CPUãƒ¢ãƒ¼ãƒ‰ã«
embedding:
  device: "cpu"  # "cuda" â†’ "cpu"
```

---

## ğŸ“Š è¨­å®šã®ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚º

### `config.yaml` ã®ä¸»è¦è¨­å®š

```yaml
# ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²ã®èª¿æ•´
index:
  chunk_size: 512        # å¤§ãã„â†’ç²¾åº¦â†‘ã€å‡¦ç†â†“
  chunk_overlap: 50      # å¤§ãã„â†’é€£ç¶šæ€§â†‘

# RAGãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
rag:
  temperature: 0.1       # 0ã«è¿‘ã„â†’æ±ºå®šçš„ã€1ã«è¿‘ã„â†’å‰µé€ çš„
  similarity_top_k: 3    # å‚ç…§ã™ã‚‹æ–‡æ›¸æ•°

# ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯è¨­å®š
benchmark:
  batch_size: 10         # ãƒ¡ãƒ¢ãƒªç¯€ç´„ã—ãŸã„å ´åˆã¯å°ã•ã
  save_interval: 50      # ä¸­é–“ä¿å­˜ã®é »åº¦
```

---

## ğŸ“ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

1. âœ… **åŸºæœ¬å‹•ä½œç¢ºèªå®Œäº†**
2. ğŸ”„ **ã‚«ã‚¹ã‚¿ãƒ è³ªå•ã§ãƒ†ã‚¹ãƒˆ**: è‡ªåˆ†ã®è³ªå•ã‚’è¿½åŠ 
3. ğŸ“Š **ãƒ•ãƒ«ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ**: 200å•ã§è©•ä¾¡
4. ğŸ”¬ **ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–**: temperatureã‚„top_kã‚’èª¿æ•´
5. ğŸ“ˆ **çµæœåˆ†æ**: ã‚«ãƒ†ã‚´ãƒªåˆ¥ã®ç²¾åº¦ã‚’ç¢ºèª

---

## ğŸ’¡ ãƒ’ãƒ³ãƒˆ

- **é«˜é€ŸåŒ–**: GPUåˆ©ç”¨ã€ãƒ¢ãƒ‡ãƒ«ã‚’INT4ã«çµ±ä¸€
- **ç²¾åº¦å‘ä¸Š**: chunk_sizeã‚’å¤§ããã€INT8ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨
- **ãƒ‡ãƒãƒƒã‚°**: å°‘æ•°ã®è³ªå•ã§ã¾ãšãƒ†ã‚¹ãƒˆ
- **ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—**: indexãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¯æ§‹ç¯‰ã«æ™‚é–“ãŒã‹ã‹ã‚‹ã®ã§ä¿å­˜æ¨å¥¨

---

**å•é¡ŒãŒè§£æ±ºã—ãªã„å ´åˆã¯ã€ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ã‚³ãƒ”ãƒ¼ã—ã¦Issueã‚’ä½œæˆã—ã¦ãã ã•ã„ï¼**
